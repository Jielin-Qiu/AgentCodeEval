# AgentCodeEval Configuration File
# Copy this file and customize for your setup

api:
  # API Keys (set via environment variables for security)
  # openai_api_key: "your-openai-key-here"
  # anthropic_api_key: "your-anthropic-key-here" 
  # google_api_key: "your-google-key-here"
  # huggingface_token: "your-hf-token-here"
  
  # Rate limiting settings
  max_requests_per_minute: 60
  max_concurrent_requests: 10
  
  # Default models - üèÜ 3 Elite Models
  default_model_openai: "o3"                                  # ‚úÖ Elite: OpenAI o3 (reasoning model)
  default_model_anthropic: "claude-sonnet-4-20250514"         # ‚úÖ Elite: Claude Sonnet 4 via AWS Bedrock
  default_model_google: "gemini-2.5-pro"                      # ‚úÖ Elite: Gemini 2.5 Pro (latest)

data:
  # Local storage directories
  output_dir: "./data/output"
  generated_dir: "./data/generated"
  templates_dir: "./data/templates"
  
  # Synthetic generation settings
  supported_languages:
    - python
    - javascript
    - typescript
    - java
    - cpp
    - go
  
  # Project generation criteria
  min_files_per_project: 5
  max_files_per_project: 100
  projects_per_language: 1  # For testing: 6 languages √ó 1 = 6 sample projects (original: 200)
  
  # Complexity levels for synthetic projects
  complexity_distribution:
    easy: 0.25      # 25% easy projects
    medium: 0.40    # 40% medium projects
    hard: 0.25      # 25% hard projects
    expert: 0.10    # 10% expert projects
  
  # Generation quality controls
  min_complexity_score: 0.3
  max_complexity_score: 0.9
  min_documentation_ratio: 0.1

benchmark:
  # Scale parameters
  total_instances: 12000
  
  # Task category distribution (must sum to total_instances)
  task_distribution:
    architectural_understanding: 1500
    cross_file_refactoring: 1500
    feature_implementation: 1900  # +100
    bug_investigation: 1600      # +100
    multi_session_development: 1200
    code_comprehension: 1600     # +100
    integration_testing: 1400    # +100
    security_analysis: 1300      # +100
  
  # Difficulty distribution (must sum to total_instances)
  difficulty_distribution:
    easy: 3200      # 10K-40K tokens
    medium: 4500    # 40K-100K tokens
    hard: 3600      # 100K-200K tokens
    expert: 700     # 200K+ tokens
  
  # Context length ranges (min_tokens, max_tokens)
  context_ranges:
    easy: [10000, 40000]
    medium: [40000, 100000]
    hard: [100000, 200000]
    expert: [200000, 500000]
  
  # Information coverage requirements
  min_information_coverage: 0.7
  target_information_coverage:
    easy: 0.75
    medium: 0.85
    hard: 0.90
    expert: 0.95

evaluation:
  # Metric weights for CADS (Composite Agent Development Score)
  # Must sum to 1.0
  metric_weights:
    architectural_coherence: 0.20
    dependency_traversal: 0.20
    multi_session_memory: 0.20
    cross_file_reasoning: 0.15
    incremental_development: 0.15
    information_coverage: 0.10
  
  # Scoring thresholds
  score_thresholds:
    excellent:
      min: 4.0
      max: 5.0
    good:
      min: 3.0
      max: 4.0
    fair:
      min: 2.0
      max: 3.0
    poor:
      min: 0.0
      max: 2.0
  
  # Timeout settings (seconds)
  task_timeout: 300      # 5 minutes per task
  session_timeout: 1800  # 30 minutes per session
  
  # Validation settings
  human_validation_ratio: 0.05  # 5% manual validation
  inter_rater_agreement_threshold: 0.8 